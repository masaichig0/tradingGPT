{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95bc4f3",
   "metadata": {},
   "source": [
    "# Interact COMET:\n",
    "\n",
    "Langchain - Comet: https://www.comet.com/docs/v2/integrations/third-party-tools/langchain/\n",
    "\n",
    "I will use the code to chat_with_news: http://localhost:8888/notebooks/PycharmProjects/tradingGPT/scripts/chat_with_news.ipynb\n",
    "\n",
    "First, prepare the data I used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from financial_data import FinancialDataFinnHub\n",
    "import os\n",
    "\n",
    "\n",
    "# Create Finnhub object\n",
    "symbol = \"NVDA\"\n",
    "api_key = os.environ.get(\"FINHUB_API_KEY\")\n",
    "nvda = FinancialDataFinnHub(symbol, api_key)\n",
    "\n",
    "# Use FinancialHub to load news url\n",
    "news_urls = nvda.company_news['url']\n",
    "urls = [news_urls.iloc[i][0] for i in range(len(news_urls))]\n",
    "\n",
    "\n",
    "# langchain UnstructuredURLLoader to load news\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()\n",
    "\n",
    "# Remove news if the content is not reacheable. \n",
    "for i, d in enumerate(data):\n",
    "    p_content = d.page_content[:22]\n",
    "    if p_content == 'Javascript is Disabled':\n",
    "        data.pop(i)\n",
    "print(f\"You got {len(data)} news to read about {symbol}. \")\n",
    "\n",
    "# Create `OpenAIEmbeddings` model\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Split text with RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "# Store vectors in Chroma \n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "comet_callback = CometCallbackHandler(\n",
    "    project_name=\"comet-example-langchain\",\n",
    "    complexity_metrics=True,\n",
    "    stream_logs=True,\n",
    "    tags=[\"agent\"],\n",
    ")\n",
    "manager = CallbackManager([StdOutCallbackHandler(), comet_callback])\n",
    "llm = OpenAI(temperature=0.9, callback_manager=manager, verbose=True)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callback_manager=manager)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    callback_manager=manager,\n",
    "    verbose=True,\n",
    ")\n",
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
    ")\n",
    "comet_callback.flush_tracker(agent, finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d30c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/masahiroichigo/comet-example-langchain/7ead0637f67044db944e05cdf297073e\n",
      "\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m The comet_ml callback is currently in beta and is subject to change based on updates to `langchain`. Please report any issues to https://github.com/comet-ml/issue_tracking/issues with the tag `langchain`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': ' The Eiffel Tower is the tallest structure in Paris, standing at 324m (1,063ft) tall. When constructed, it was the tallest man-made structure in the world until the Chrysler Building in New York City was built in 1930. In 1957, an aerial was added to the top of the tower, making it taller than the Chrysler Building by 5.2m (17ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/masahiroichigo/comet-example-langchain/7ead0637f67044db944e05cdf297073e\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     openai_completion_tokens : 110\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     openai_prompt_tokens     : 224\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     openai_total_tokens      : 334\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_25%      : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_50%      : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_75%      : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_count    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_max      : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_mean     : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_min      : 0.5352112676056339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rougeLsum_score_std      : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : langchain\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__type             : openai\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_best_of           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_frequency_penalty : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_logit_bias        : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_tokens        : 256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_model_name        : text-davinci-003\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_n                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_presence_penalty  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_request_timeout   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_temperature       : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_top_p             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                        : 2 (1.93 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataframe                    : 1 (2.67 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (250.45 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (858 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample                  : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "class Rouge:\n",
    "    def __init__(self, reference):\n",
    "        self.reference = reference\n",
    "        self.scorer = rouge_scorer.RougeScorer([\"rougeLsum\"], use_stemmer=True)\n",
    "\n",
    "    def compute_metric(self, generation, prompt_idx, gen_idx):\n",
    "        prediction = generation.text\n",
    "        results = self.scorer.score(target=self.reference, prediction=prediction)\n",
    "\n",
    "        return {\n",
    "            \"rougeLsum_score\": results[\"rougeLsum\"].fmeasure,\n",
    "            \"reference\": self.reference,\n",
    "        }\n",
    "\n",
    "\n",
    "reference = \"\"\"\n",
    "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.\n",
    "It was the first structure to reach a height of 300 metres.\n",
    "\n",
    "It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)\n",
    "Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France .\n",
    "\"\"\"\n",
    "rouge_score = Rouge(reference=reference)\n",
    "\n",
    "template = \"\"\"Given the following article, it is your job to write a summary.\n",
    "Article:\n",
    "{article}\n",
    "Summary: This is the summary for the above article:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"article\"], template=template)\n",
    "\n",
    "comet_callback = CometCallbackHandler(\n",
    "    project_name=\"comet-example-langchain\",\n",
    "    complexity_metrics=False,\n",
    "    stream_logs=True,\n",
    "    tags=[\"custom_metrics\"],\n",
    "    custom_metrics=rouge_score.compute_metric,\n",
    ")\n",
    "manager = CallbackManager([StdOutCallbackHandler(), comet_callback])\n",
    "llm = OpenAI(temperature=0.9, callback_manager=manager, verbose=True)\n",
    "\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callback_manager=manager)\n",
    "\n",
    "test_prompts = [\n",
    "    {\n",
    "        \"article\": \"\"\"\n",
    "                 The tower is 324 metres (1,063 ft) tall, about the same height as\n",
    "                 an 81-storey building, and the tallest structure in Paris. Its base is square,\n",
    "                 measuring 125 metres (410 ft) on each side.\n",
    "                 During its construction, the Eiffel Tower surpassed the\n",
    "                 Washington Monument to become the tallest man-made structure in the world,\n",
    "                 a title it held for 41 years until the Chrysler Building\n",
    "                 in New York City was finished in 1930.\n",
    "\n",
    "                 It was the first structure to reach a height of 300 metres.\n",
    "                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,\n",
    "                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).\n",
    "\n",
    "                 Excluding transmitters, the Eiffel Tower is the second tallest\n",
    "                 free-standing structure in France after the Millau Viaduct.\n",
    "                 \"\"\"\n",
    "    }\n",
    "]\n",
    "print(synopsis_chain.apply(test_prompts))\n",
    "comet_callback.flush_tracker(synopsis_chain, finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672599f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from comet_ml import Experiment\n",
    "          \n",
    "experiment = Experiment(\n",
    "  api_key = os.environ.get(\"COMET_API_KEY\"),\n",
    "  project_name = \"general\",\n",
    "  workspace=\"masahiroichigo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e477e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd5f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
