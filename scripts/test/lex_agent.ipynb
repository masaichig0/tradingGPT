{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e8e628",
   "metadata": {},
   "source": [
    "# Demonstration from pinecone webiner:\n",
    "\n",
    "Source code: https://colab.research.google.com/drive/1ZbXzzMFyMQ-nQf-gQXWAv4IRDI90rXpa?usp=sharing&_hsmi=255277680#scrollTo=8Br4lPWNmZYy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1eeae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU datasets pinecone-client[grpc] langchain openai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a76720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = \"us-east4-gcp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44b3e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Masa/.cache/huggingface/datasets/jamescalam___json/jamescalam--lex-transcripts-6a9688b7915283fe/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'channel_id', 'title', 'published', 'transcript', 'source'],\n",
       "    num_rows: 499\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\n",
    "    'jamescalam/lex-transcripts',\n",
    "    split='train'\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fd32f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': '_SpptYg_0Rs',\n",
       " 'channel_id': 'UCSHZKyawb77ixDdsGog4iWA',\n",
       " 'title': 'Are We Living in a Simulation? with George Hotz and Lex Fridman | AI Podcast Clips',\n",
       " 'published': datetime.datetime(2019, 8, 29, 13, 9, 2),\n",
       " 'transcript': \" Do you think we're living in a simulation? Yes, but it may be unfalsifiable. What do you mean by unfalsifiable? So if the simulation is designed in such a way that they did like a formal proof to show that no information can get in and out, and if their hardware is designed for anything in the simulation to always keep the hardware in spec, it may be impossible to prove whether we're in a simulation or not. So they've designed it such that it's a closed system, you can't get outside the system? Well maybe it's one of three worlds. We're either in a simulation which can be exploited, we're in a simulation which not only can't be exploited, but like the same thing is true about VMs. A really well designed VM, you can't even detect if you're in a VM or not. That's brilliant. So we're, yeah, so the simulation is running on a virtual machine. But now in reality, all VMs have ways to detect. That's the point. I mean, is it, you've done quite a bit of hacking yourself, and so you should know that really any complicated system will have ways in and out. So this isn't necessarily true going forward. I spent my time away from Kama, I learned Coq, it's a dependently typed, like, it's a language for writing math proofs. And if you write code that compiles in a language like that, it is correct by definition. The types check its correctness. So it's possible that the simulation is written in a language like this, in which case, you know. Yeah, but that can't be sufficiently expressive a language like that. Oh, it can. It can be? Oh, yeah. Okay. Well, so, all right, so. The simulation doesn't have to be Turing complete if it has a scheduled end date. Looks like it does, actually, with entropy. I mean, I don't think that a simulation that results in something as complicated as the universe would have a form of proof of correctness, right? It's possible, of course. We have no idea how good their tooling is, and we have no idea how complicated the universe computer really is. It may be quite simple. It's just very large, right? It's definitely very large. But the fundamental rules might be super simple. Yeah, Conway's Game of Life kind of stuff. So if you could hack, so imagine a simulation that is hackable, if you could hack it, what would you change about the universe? How would you approach hacking a simulation? The reason I gave that talk... By the way, I'm not familiar with the talk you gave. I just read that you talked about escaping the simulation or something like that. So maybe you can tell me a little bit about the theme and the message there, too. It wasn't a very practical talk about how to actually escape a simulation. It was more about a way of restructuring an us versus them narrative. If we continue on the path we're going with technology, I think we're in big trouble as a species, and not just as a species, but even as me as an individual member of the species. So if we could change rhetoric to be more like to think upwards, like to think about that we're in a simulation and how we could get out, already we'd be on the right path. What you actually do once you do that, well, I assume I would have acquired way more intelligence in the process of doing that. So I'll just ask that. So the thinking upwards, what kind of breakthrough ideas do you think thinking in that way could inspire? And why did you say upwards? Upwards. Into space? Are you thinking sort of exploration in all forms? The space narrative that held for the modernist generation doesn't hold as well for the post-modern generation. What's the space narrative? Are we talking about the same space? The three-dimensional space? No, no, space, like going up to space. Literally space, yeah. Like building, like Elon Musk, like we're going to build rockets, we're going to go to Mars, we're going to colonize the universe. And the narrative you're referring, I was born in the Soviet Union, you're referring to the race to space. The race to space, yes. The space to explore, okay. That was a great modernist narrative. It doesn't seem to hold the same weight in today's culture. I'm hoping for good post-modern narratives that replace it. So let's think, so you work a lot with AI. So AI is one formulation of that narrative. There could be also, I don't know how much you do in VR and AR. That's another, I know less about it, but every time I play with it in our research, it's fascinating, that virtual world. Are you interested in the virtual world? I would like to move to virtual reality. In terms of your work? No, I would like to physically move there. The apartment I can rent in the cloud is way better than the apartment I can rent in the real world. Well, it's all relative, isn't it? Because others will have very nice apartments too, so you'll be inferior in the virtual world as well. But that's not how I view the world, right? I don't view the world, I mean, that's a very like almost zero-sum-ish way to view the world. Say like my great apartment isn't great because my neighbor has one too. No, my great apartment is great because like, look at this dishwasher, man. You just touch the dish and it's washed, right? And that is great in and of itself if I have the only apartment or if everybody had the apartment, I don't care. So you have fundamental gratitude.\",\n",
       " 'source': 'https://youtu.be/_SpptYg_0Rs'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab6394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')  # cl100k base is encoder used by ada-002\n",
    "\n",
    "# define a length function\n",
    "def tiktoken_len(text: str) -> int:\n",
    "    tokens = tokenizer.encode(text, disallowed_special=())\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988614a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken_len(\"here is a random sentence we can get the token length for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ada8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,  # number of tokens overlap between chunks\n",
    "    length_function=tiktoken_len,  # token count function\n",
    "    separators=['\\n\\n', '.\\n', '\\n', '.', '?', '!', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677492fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a776d7c4afe74023af86b9bbfedc7507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for row in tqdm(data):\n",
    "    chunks = text_splitter.split_text(row['transcript'])\n",
    "    row.pop('transcript')\n",
    "    for i, text in enumerate(chunks):\n",
    "        new_data.append({**row, **{'chunk': i, 'text': text}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c979958f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': '_SpptYg_0Rs',\n",
       " 'channel_id': 'UCSHZKyawb77ixDdsGog4iWA',\n",
       " 'title': 'Are We Living in a Simulation? with George Hotz and Lex Fridman | AI Podcast Clips',\n",
       " 'published': datetime.datetime(2019, 8, 29, 13, 9, 2),\n",
       " 'source': 'https://youtu.be/_SpptYg_0Rs',\n",
       " 'chunk': 0,\n",
       " 'text': \"Do you think we're living in a simulation? Yes, but it may be unfalsifiable. What do you mean by unfalsifiable? So if the simulation is designed in such a way that they did like a formal proof to show that no information can get in and out, and if their hardware is designed for anything in the simulation to always keep the hardware in spec, it may be impossible to prove whether we're in a simulation or not. So they've designed it such that it's a closed system, you can't get outside the system? Well maybe it's one of three worlds. We're either in a simulation which can be exploited, we're in a simulation which not only can't be exploited, but like the same thing is true about VMs. A really well designed VM, you can't even detect if you're in a VM or not. That's brilliant. So we're, yeah, so the simulation is running on a virtual machine. But now in reality, all VMs have ways to detect. That's the point. I mean, is it, you've done quite a bit of hacking yourself, and so you should know that really any complicated system will have ways in and out. So this isn't necessarily true going forward. I spent my time away from Kama, I learned Coq, it's a dependently typed, like, it's a language for writing math proofs. And if you write code that compiles in a language like that, it is correct by definition. The types check its correctness. So it's possible that the simulation is written in a language like this, in which case, you know. Yeah, but that can't be sufficiently expressive a language like that. Oh, it can. It can be? Oh, yeah. Okay. Well, so, all right, so. The simulation doesn't have to be Turing complete if it has a scheduled end date. Looks like it does, actually, with entropy. I mean, I don't think that a simulation that results in something as complicated as the universe would have a form of proof of correctness, right? It's possible, of course. We have no idea how good their tooling is, and we have no idea how complicated the universe computer really is. It may be quite simple. It's just very large, right? It's definitely very large. But the fundamental rules might be super simple. Yeah, Conway's Game of Life kind of stuff. So if you could hack, so imagine a simulation that is hackable, if you could hack it, what would you change about the universe? How would you approach hacking a simulation? The reason I gave that talk... By the way, I'm not familiar with the talk you gave. I just read that you talked about escaping the simulation or something like that. So maybe you can tell me a little bit about the theme and the message there, too. It wasn't a very practical talk about how to actually escape a simulation. It was more about a way of restructuring an us versus them narrative. If we continue on the path we're going with technology, I think we're in big trouble as a species, and not just as a species, but even as me as an individual member of the species. So if we could change rhetoric to be more like to think upwards, like to think about that we're in a simulation and how we could get out, already we'd be on the right path. What you actually do once you do that, well, I assume I would have acquired way more intelligence in the process of doing that. So I'll just ask that. So the thinking upwards, what kind of breakthrough ideas do you think thinking in that way could inspire? And why did you say upwards? Upwards. Into space? Are you thinking sort of exploration in all forms? The space narrative that held for the modernist generation doesn't hold as well for the post-modern generation. What's the space narrative? Are we talking about the same space? The three-dimensional space? No, no, space, like going up to space. Literally space, yeah. Like building, like Elon Musk, like we're going to build rockets, we're going to go to Mars, we're going to colonize the universe. And the narrative you're referring, I was born in the Soviet Union, you're referring to the race to space. The race to space, yes. The space to explore, okay. That was a great modernist narrative. It doesn't seem to hold the same weight in today's culture. I'm hoping for good post-modern narratives that replace it. So let's think, so you work a lot with AI. So AI is one formulation of that narrative. There could be also, I don't know how much you do in VR and AR\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8d0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873fceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # app.pinecone.io\n",
    "    environment=PINECONE_ENV  # next to API key in console\n",
    ")\n",
    "\n",
    "index_name = \"lex-agent\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name, dimension=1536\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e1c92c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cd80121535481385b265c3a8e4ec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(new_data), batch_size)):\n",
    "    # get end of batch\n",
    "    i_end = min(len(new_data), i+batch_size)\n",
    "    # get batch of records\n",
    "    metadatas = new_data[i:i_end]\n",
    "    ids = [f\"{meta['video_id']}-{meta['chunk']}\" for meta in metadatas]\n",
    "    texts = [meta['text'] for meta in metadatas]\n",
    "    xc = embeddings.embed_documents(texts)\n",
    "    to_upsert = zip(ids, xc, metadatas)\n",
    "    # now add to Pinecone vec DB\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd476f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "vectordb = Pinecone(\n",
    "    index=index,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    text_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1d37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f5b29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f63554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_desc = \"\"\"Use this tool to answer user questions using Lex\n",
    "Fridman podcasts. If the user states 'ask Lex' use this tool to get\n",
    "the answer. This tool can also be used for follow up questions from\n",
    "the user.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1aa6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [Tool(\n",
    "    func=retriever.run,\n",
    "    description=tool_desc,\n",
    "    name='Lex Fridman DB'\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "962475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",  # important to align with agent prompt (below)\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5dbb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description', \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=2,\n",
    "    early_stopping_method=\"generate\",\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40dc0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "926e15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"You are a helpful chatbot that answers the user's questions.\n",
    "\"\"\"\n",
    "\n",
    "prompt = conversational_agent.agent.create_prompt(\n",
    "    system_message=sys_msg,\n",
    "    tools=tools\n",
    ")\n",
    "conversational_agent.agent.llm_chain.prompt = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3543adfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6013d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input', 'chat_history', 'agent_scratchpad']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1a4c949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history'),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fffda86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06493505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful chatbot that answers the user's questions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbcdd247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagesPlaceholder(variable_name='chat_history')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "689b8ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent.agent.llm_chain.prompt.messages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a50c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> Lex Fridman DB: Use this tool to answer user questions using Lex\n",
      "Fridman podcasts. If the user states 'ask Lex' use this tool to get\n",
      "the answer. This tool can also be used for follow up questions from\n",
      "the user.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"action\": string \\ The action to take. Must be one of Lex Fridman DB\n",
      "    \"action_input\": string \\ The input to the action\n",
      "}}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\ You should put what you want to return to use here\n",
      "}}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "{input}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    conversational_agent.agent.llm_chain.prompt.messages[2].prompt.template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c9c1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi how are you',\n",
       " 'chat_history': [],\n",
       " 'output': \"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent(\"hi how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77209e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Lex Fridman DB\",\n",
      "    \"action_input\": \"What did Lex Fridman say about the future of AI?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLex Fridman discussed the potential for AI to become companions and proliferate in the digital space, but he also emphasized the importance of democratizing AI and preventing large tech companies from using it to control human beings. He also expressed his belief that AI will not become our masters, but rather, humans will become the masters of AI. Additionally, he discussed the concern that automation and powerful AI will lead to job loss, but he believes that ultimately, technology will enhance human intelligence and create new job opportunities. Finally, he highlighted the theme of his upcoming book, Singularity's Nearer, which argues that things are getting better in all aspects of life.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Based on Lex Fridman's discussions, he believes that AI will not become our masters, but rather, humans will become the masters of AI. He also believes that technology will enhance human intelligence and create new job opportunities. Finally, he argues that things are getting better in all aspects of life in his upcoming book, Singularity's Nearer.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ask lex about the future of ai',\n",
       " 'chat_history': [HumanMessage(content='hi how are you', additional_kwargs={}),\n",
       "  AIMessage(content=\"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\", additional_kwargs={})],\n",
       " 'output': \"Based on Lex Fridman's discussions, he believes that AI will not become our masters, but rather, humans will become the masters of AI. He also believes that technology will enhance human intelligence and create new job opportunities. Finally, he argues that things are getting better in all aspects of life in his upcoming book, Singularity's Nearer.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent(\"ask lex about the future of ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb1720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Lex Fridman DB\",\n",
      "    \"action_input\": \"What does Lex Fridman think about space exploration?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLex Fridman is a strong advocate for space exploration and believes that it is important for humanity to expand beyond Earth. He has had several guests on his podcast who share this view, including Eric Weinstein, who also believes that getting off this planet is crucial for the survival and progress of humanity. Lex has also expressed interest in the potential for extraterrestrial life and the possibility of visiting other worlds.\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "conversational_agent(\"what does he think about space exploration?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd5729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
